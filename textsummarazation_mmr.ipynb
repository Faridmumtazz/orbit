{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " textsummarazation_mmr.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkMUI8M4AVfF"
      },
      "source": [
        "# Text Summarization Menggunakan Metode Maximum Marginal Relevance (MMR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqDbscl0iZ0-"
      },
      "source": [
        "Link repo github kode: https://github.com/fajri91/Text-Summarization-MMR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KR2ocu6eylq"
      },
      "source": [
        "# Ketik kode disini\n",
        "!pip install sastrawi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVPx6GKACYwK"
      },
      "source": [
        "# Import modul (tools)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IbucIzCehvD"
      },
      "source": [
        "# Ketik kode disini\n",
        "import re\n",
        "import requests\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import operator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em5Pum5WDrOa"
      },
      "source": [
        "# Tahap Stemming pada teks berbahasa Indonesia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0e4PRQKfUdy"
      },
      "source": [
        "# Ketik kode disini\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SsOTOK-ED-y"
      },
      "source": [
        "# Load stopwords list dari repo github, yang akan dipakai untuk menghapus stopwords yang ada di teks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b14tU-3hfyWn"
      },
      "source": [
        "url: https://raw.githubusercontent.com/Wayan123/Sentiment-Analysis/main/stopwordlist.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPwwCDQsfdai"
      },
      "source": [
        "# Ketik kode disini\n",
        "def load_stopWords():\n",
        "  url = \"https://filesamples.com/samples/document/txt/sample3.txt\"\n",
        "  ina_stopword = requests.get(url).content\n",
        "  return ina_stopword.split()\n",
        "\n",
        "stopwords = load_stopWords()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7822gIXErts"
      },
      "source": [
        "# Kita bisa melihat list stopwords dengan run stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTPAFcKUEgfc"
      },
      "source": [
        "# Ketik kode disini\n",
        "stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ_jZFndI40b"
      },
      "source": [
        "## Membuat fungsi untuk stemmer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IwDHuGZgTyr"
      },
      "source": [
        "# Ketik kode diisni\n",
        "def cleanData(sentence):\n",
        "  ret = []\n",
        "  sentence = stemmer.stem(sentence)\n",
        "  for word in sentence.split():\n",
        "    if not word in stopwords:\n",
        "      ret.append(word)\n",
        "  return \" \".join(ret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXv7mivzJC_h"
      },
      "source": [
        "## Membuat fungsi untuk vektor kata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9K_aT02gXHK"
      },
      "source": [
        "# Ketik kode diisni\n",
        "def getVectorSpace(cleanSet):\n",
        "  vocab = {}\n",
        "  for data in cleanSet:\n",
        "    for word in data.split():\n",
        "      vocab[data] = 0\n",
        "  return vocab.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqMsFQNNJHeJ"
      },
      "source": [
        "## Membuat fungsi untuk menghitung cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gZH0RdcgYOS"
      },
      "source": [
        "# Fungsi untuk menghitung cosine similarity\n",
        "def calculateSimilarity(sentence, doc):\n",
        "  if doc == []:\n",
        "    return 0\n",
        "  vocab = {}\n",
        "  for word in sentence:\n",
        "    vocab[word] = 0\n",
        "\n",
        "  docInOneSentence = '';\n",
        "  for t in doc:\n",
        "    docInOneSentence += (t + ' ')\n",
        "    for word in t.split():\n",
        "      vocab[word]=0\n",
        "  \n",
        "  cv = CountVectorizer(vocabulary=vocab.keys())\n",
        "\n",
        "  docVector = cv.fit_transform([docInOneSentence])\n",
        "  sentenceVector = cv.fit_transform([sentence])\n",
        "  return cosine_similarity(docVector, sentenceVector)[0][0]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqo_fuWeJgna"
      },
      "source": [
        "# Load raw data teks dari repo github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv-0pAAZgyXh"
      },
      "source": [
        "url: https://raw.githubusercontent.com/fajri91/Text-Summarization-MMR/master/news_data4.txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb3RroXfkqmo"
      },
      "source": [
        "# Load raw data \n",
        "r = requests.get('https://filesamples.com/samples/document/txt/sample3.txt')\n",
        "r.encoding = r.apparent_encoding\n",
        "texts = r.text.split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOmOJsMQKF1V"
      },
      "source": [
        "# Menampilkan text yang akan di ringkas\n",
        "texts\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQcOqxiM_kGb"
      },
      "source": [
        "sentences = []\n",
        "clean = []\n",
        "originalSentenceOf = {}\n",
        "\n",
        "for line in texts:\n",
        "  parts = line.split('.')\n",
        "  for part in parts:\n",
        "    cl = cleanData(part)\n",
        "    sentences.append(part)\n",
        "    clean.append(cl)\n",
        "    originalSentenceOf[cl] = part\n",
        "setClean = set(clean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-Vps_QFKkJS"
      },
      "source": [
        "## Menghitung nilai cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMxfgulV_qPS"
      },
      "source": [
        "#calculate Similarity score each sentence with whole documents\t\t\n",
        "scores = {}\n",
        "for data in clean:\n",
        "  temp_doc = setClean - set([data])\n",
        "  score = calculateSimilarity(data, list(temp_doc))\n",
        "  scores[data] = score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg9HHr_t_wnt"
      },
      "source": [
        "#calculate MMR\n",
        "n = 20 * len(sentences) / 100\n",
        "alpha = 0.5\n",
        "summarySet = []\n",
        "while n > 0:\n",
        "  mmr = {}\n",
        "\n",
        "\n",
        "  for sentence in scores.keys():\n",
        "    if not sentence in summarySet:\n",
        "      mmr[sentence] = alpha * scores[sentence] - (1-alpha) * calculateSimilarity(sentence, summarySet)\n",
        "      selected = max(mmr.items(), key=operator.itemgetter(1))[0]\n",
        "      summarySet.append(selected)\n",
        "      n -= 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppXG2eC_LW7o"
      },
      "source": [
        "## Menampilkan hasil Summary dari hasil perhitungan Algoritma MMR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN-YLi1w_5j0"
      },
      "source": [
        "# Menampilkan hasil Summary\n",
        "print ('\\nSummary (hasil teks yang diringkas):\\n')\n",
        "for sentence in summarySet:\n",
        "  print (originalSentenceOf [sentence].lstrip(' '))\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI55e5PCLffv"
      },
      "source": [
        "## Menampilkan perbandingan Summary text dengan teks asli sebelum si summary. Setiap kalimat yang di jadikan sebagai summary akan di highlight merah."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM6KLPjighgE"
      },
      "source": [
        "print ('==========================================================================')\n",
        "print ('\\nOriginal Passages (Teks Asli):\\n')\n",
        "from termcolor import colored\n",
        "\n",
        "for sentence in clean:\n",
        "  if sentence in summarySet:\n",
        "    print (colored(originalSentenceOf[sentence].lstrip(' '), 'yellow'))\n",
        "  else:\n",
        "    print (originalSentenceOf[sentence].lstrip(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAnMcNWMlv8A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}